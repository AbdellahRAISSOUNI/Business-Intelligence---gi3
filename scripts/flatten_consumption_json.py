"""
Flatten JSON consumption files (electricity, water, gas) into staging CSVs.

This script is a lightweight \"extraction\" helper: PDI will then work from the
staging CSVs, which is still compliant with the ETL requirements.

Input JSON files (already generated by generate_mock_data.py):
- data_sources/json/Electricite_consumption_01_2025.json
- data_sources/json/Eau_consumption_01_2025.json
- data_sources/json/Gaz_consumption_01_2025.json

Output CSV files:
- staging/consumption_electricite.csv
- staging/consumption_eau.csv
- staging/consumption_gaz.csv
"""

from __future__ import annotations

import csv
import json
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent
JSON_DIR = BASE_DIR / "data_sources" / "json"
STAGING_DIR = BASE_DIR / "staging"


def flatten_file(energy: str, json_name: str, consommation_field: str) -> None:
    """
    Flatten a single JSON file into a staging CSV.
    energy: logical energy name (electricite, eau, gaz)
    json_name: file name in JSON_DIR
    consommation_field: 'consommation_kWh' or 'consommation_m3'
    """
    in_path = JSON_DIR / json_name
    out_path = STAGING_DIR / f"consumption_{energy}.csv"
    STAGING_DIR.mkdir(parents=True, exist_ok=True)

    with in_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    id_region = data.get("id_region")
    rows = []

    for bat in data.get("batiments", []):
        id_batiment = bat.get("id_batiment")
        type_energie = bat.get("type_energie")
        unite = bat.get("unite")
        date_generation = bat.get("date_generation")

        for m in bat.get("mesures", []):
            rows.append(
                {
                    "id_region": id_region,
                    "id_batiment": id_batiment,
                    "type_energie": type_energie,
                    "unite": unite,
                    "date_generation": date_generation,
                    "compteur_id": m.get("compteur_id"),
                    "date_mesure": m.get("date_mesure"),
                    "consommation": m.get(consommation_field),
                }
            )

    fieldnames = [
        "id_region",
        "id_batiment",
        "type_energie",
        "unite",
        "date_generation",
        "compteur_id",
        "date_mesure",
        "consommation",
    ]

    with out_path.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

    print(f"Wrote {len(rows)} rows to {out_path}")


def main() -> None:
    flatten_file(
        energy="electricite",
        json_name="Electricite_consumption_01_2025.json",
        consommation_field="consommation_kWh",
    )
    flatten_file(
        energy="eau",
        json_name="Eau_consumption_01_2025.json",
        consommation_field="consommation_m3",
    )
    flatten_file(
        energy="gaz",
        json_name="Gaz_consumption_01_2025.json",
        consommation_field="consommation_m3",
    )


if __name__ == "__main__":
    main()


